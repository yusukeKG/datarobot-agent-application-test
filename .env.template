# Your DataRobot API token.
# Refer to https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#configure-your-environment for help.
DATAROBOT_API_TOKEN=

# The URL of your DataRobot instance API.
DATAROBOT_ENDPOINT=https://app.datarobot.com/api/v2

# Local endpoint for writer agent component
WRITER_AGENT_ENDPOINT=http://localhost:8842

# The Pulumi stack name to use for this project.
PULUMI_STACK_NAME=agent-application-dev

# If empty, a blank passphrase will be used
PULUMI_CONFIG_PASSPHRASE=123

# Skip Pulumi update check to prevent issues with rate limiting
PULUMI_SKIP_UPDATE_CHECK=1

# If empty, a new use case will be created
DATAROBOT_DEFAULT_USE_CASE=

# If empty, a new execution environment will be created for each agent using the docker_context folder
DATAROBOT_DEFAULT_EXECUTION_ENVIRONMENT="[DataRobot] Python 3.11 GenAI Agents"

# Required: Random string for Web application security. We recommend a long password generated securely such as:
# `python -c "import os, binascii; print(binascii.hexlify(os.urandom(64)).decode('utf-8'))"`
SESSION_SECRET_KEY=

# OAuth configurtion: See README instructions for getting Google and Box OAuth Apps
# GOOGLE_CLIENT_ID=
# GOOGLE_CLIENT_SECRET=

# BOX_CLIENT_ID=
# BOX_CLIENT_SECRET=

# LLM Configuration:
# Agent templates support multiple flexible LLM options including:
# - LLM Gateway Direct (default)
# - External LLM
# - Already Deployed Text Generation model in DataRobot
#
# You can edit the LLM configuration by manually changing which configuration is
# active (recommended option).
# Simply run `ln -sf ../configurations/<chosen_configuration> llm.py`
# from the `infra/infra` folder
#
# If you want to do it dynamically however, you can also set it as a configuration value with:
# INFRA_ENABLE_LLM=<chosen_configuration>
# from the list of options in the infra/configurations/llm folder
# Here are some examples of each of those configuration using the dynamic option described above:

# If you want to use the LLM Gateway direct (default)
# INFRA_ENABLE_LLM=gateway_direct.py

# If you want to choose an existing LLM Deployment in DataRobot
# uncomment and configure these:
# TEXTGEN_DEPLOYMENT_ID=<your_deployment_id>
# INFRA_ENABLE_LLM=deployed_llm.py

# If you want to configure an LLM with an external LLM provider
# like Azure, Bedrock, Anthropic, or VertexAI (or all 4). Here we provide
# an Azure AI example, see:
# https://docs.datarobot.com/en/docs/gen-ai/playground-tools/deploy-llm.html
# for details on other providers and details:
# INFRA_ENABLE_LLM=blueprint_with_external_llm.py
# LLM_DEFAULT_MODEL="azure/gpt-4o"
# OPENAI_API_VERSION='2024-08-01-preview'
# OPENAI_API_BASE='https://<your_custom_endpoint>.openai.azure.com'
# OPENAI_API_DEPLOYMENT_ID='<your deployment_id>'
# OPENAI_API_KEY='<your_api_key>'

# MCP server configurations
MCP_SERVER_PORT=9000
APP_LOG_LEVEL=CRITICAL